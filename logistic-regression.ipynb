{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5ddfce1-fa61-4a73-8585-1c477e71a670",
   "metadata": {},
   "source": [
    "# Описание и пример реализации алгоритма логистической регрессии"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "319e6f22-d608-4be5-88c5-c83be82687ff",
   "metadata": {},
   "source": [
    "Логистическая регрессия (или логит-модель) - это статистический метод для анализа набора данных, используемый для прогнозирования вероятности некоторого события путем его сравнения с логистической кривой (сигмоидой).\n",
    "\n",
    "Для того, чтобы получать вероятность класса из значиний от минус бесконечности до плюс бесконечности, используется следующие преобразования. Пусть вероятность положительного события будет Р+.  Тогда вероятность второго класса будет (1-Р+). Составляется величина OR - соотношение классов. OR = P+ / (1 - P+). Она показывает отношение вероятностей того, произойдет ли исследуемое событие или не произойдет. При этом величины Р+ и соотношение классов содержат одинаковую по сути информацию. Но Р+ принадлежит интервалу от 0 до 1, а OR - от ноля до плюс бесконечности. Если рассмотреть величину логарифма отношения шансов log(OR), то увидим, что она измеряется от минус бесконечности, до плюс бесконечности. А такую величину можно прогнозировать регрессионной моделью.\n",
    "\n",
    "Пусть теперь мы прогнозируем  logOR  с помощью линейной регрессии:  $logOR=w^{T}x$ . Как из этой величины получить P+?\n",
    "\n",
    "$P+ = \\dfrac{OR}{1+OR}=\\dfrac{e^{logOR}}{1+e^{logOR}} = \\dfrac{e^{w^{T}x}}{1+e^{w^{T}x}} = \\dfrac{1}{1+e^{−w^{T}x}}.$\n",
    "\n",
    "Получили функцию $\\dfrac{1}{1+e^{−w^{T}x}}$, называемую сигмоидой или логистической функцией. Так мы будем прогнозировать вероятность принадлежности объекта к классу 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c2faed6",
   "metadata": {},
   "source": [
    "Как выбрать функцию потерь (считать ошибку модели) в случае бинарной классификации?\n",
    "\n",
    "В модели логистическая регрессия используется метод максимального правдоподобия. Он основан на том, что вся информация о статистической выборке содержится в функции правдоподобия. Цель метода - поиск таких значений параметров модели, при которых максимизируется фукнция правдоподобия. Или минимизируется фукнция с противоположным знаком.\n",
    "Из функции правдоподобия выборки выводится логистическая функция потерь: $L_{log}(z) = log(1+e^{−z})$. Минимизируя эту функцию мы уменьшаем количество ошибок классификации:\n",
    "$$ L(y, y_{pred})=   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0, & if  y = y_{pred}, \\\\\n",
    "      1, & if  y != y_{pred}. \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf574aeb-83d3-44ec-b31f-03bae537147a",
   "metadata": {},
   "source": [
    "Рассмотрим функцию бинарной кросс энтропии BCELoss(_BinaryCrossEntropy_ Loss)  \n",
    "$L = \\dfrac{1}{N} \\sum_{i=1}^{N}\\left[y_{act} \\cdot ln(y_{pred}) + (1-y_{act}) \\cdot ln(1-y_{pred})\\right] = $\n",
    "\n",
    "$ = \\dfrac{1}{N} \\sum_{i=1}^{N}\\left[y_{act} \\cdot ln(\\sigma(\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n)) + (1-y_{act}) \\cdot ln(1-(\\sigma(\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n))\\right]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33efdc6e-8011-402c-843c-da2940de2c0e",
   "metadata": {},
   "source": [
    "*  Возьмем функцию потерь на одном объекте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e3b1d-585d-4426-bb36-7293f5d34bac",
   "metadata": {},
   "source": [
    "$L = y_{act} \\cdot ln(y_{pred}) + (1-y_{act}) \\cdot ln(1-y_{pred})$\n",
    "\n",
    "$y_{act} - $ реальное значение, которое принимает наша величина\n",
    "\n",
    "$y_{pred} - $ значение(_в виде вероятности!_), которое будет предсказывать наша модель\n",
    "\n",
    "Наше желание, чтобы модель, давала вероятность близкую к 1 в случае, если реальное значение 1 и вероятность близкую к нулю, в случае, если реальное значение равно нулю\n",
    "\n",
    "* Как это сделать?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9157d07-6652-427b-ba7a-dff78cdb9a0c",
   "metadata": {},
   "source": [
    "мы знаем, что в случае Логистической регрессии, наше предсказание:  \n",
    "\n",
    "$y_{pred} = \\sigma(w_0 + x_1 * w_1 + x_2 * w_2 + x_3 * w_3 ... + x_n * w_n)$\n",
    "\n",
    "\n",
    "$w_1, w_2, ..., w_n$ - настраиваемые параметры.\n",
    "\n",
    "А значит задача сводится к тому, чтобы минимизировать функцию $L$ правильно подобрав $w_1, w_2, ..., w_n$. Для этого нам нужен градиент!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c85f4ef9-45c1-4251-a3e5-6df6c455fdf8",
   "metadata": {},
   "source": [
    "$L(\\vec{w})$ - сложная функция, которая состоит из:  \n",
    "* логарифмирования\n",
    "* взятия сигмоиды \n",
    "* домножения наших $\\omega$ на константу\n",
    "\n",
    "(_Смотреть выше расписанную формулу бинарной кросс энтропии_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0e7a7fc-6dd7-4514-8344-8cac1f1f7a75",
   "metadata": {},
   "source": [
    "Посчитаем для $L = y_{act} \\cdot ln(y_{pred}) + (1-y_{act}) \\cdot ln(1-y_{pred})$ сложную частную производную по $w_1$.\n",
    "\n",
    "$L'(w_{1}) = -y_{act} * (ln(y_{pred}))' * (y_{pred})' * (w_{1}x_{1})' + (1 - y_{act}) * (ln(1 - y_{pred}))' * (y_pred)' * (w_{1}x_{1})' = (y_{pred}-y_{act}) * x_{1}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb2d2b2f-39d4-4c2c-b2f1-e77ea4178f0a",
   "metadata": {},
   "source": [
    "Посчитаем частную производную для свободного члена $w_0$.\n",
    "\n",
    "$L(w_{0}) = (y_{pred}-y_{act})$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb8dfa12-4074-4b4e-a322-60e294adbdcb",
   "metadata": {},
   "source": [
    "Математически градиент готов, останется обернуть его в алгоритм градиентного спуска и на реальных данных, где у нас не один объект, а много сразу.\n",
    "Единственной разницей того, что объектов много сразу, мы будем минимизировать функцию потерь в среднем на всех элементах.\n",
    "\n",
    "то есть обновление происходит следующим образом:\n",
    "    \n",
    "$\\vec{w_{new}} = \\vec{w_{current}} - lr * grad L(\\vec{w_{current}})$\n",
    "\n",
    "1. Высчитывается градиент на каждом из объектов (везде получаются разные $\\omega_{current}$).\n",
    "2. Берется средний $\\vec{\\omega_{current}}$ - по нему вычисляется новый $\\vec{w_{new}}$\n",
    "\n",
    "Итого:\n",
    "\n",
    "$\\vec{w_{new}} = \\vec{w_{current}} - lr * mean(grad L(\\vec{w_{current}}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d23c114-3ce5-4c63-bc51-73500b0595c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c735b118-30f9-494f-9715-9a7cbe6b3a0a",
   "metadata": {},
   "source": [
    "Создаем класс LogReg. При инициализации даем возможность указать learning_rate. Записываем эту информацию в атрибут класса. Опишишем метод fit, который будет принимать на вход X, y (X - данные x1, x2, ..., xn, y - это $y_{act})$ и высчитывать с помощью градиентного спуска самые оптимальные параметры w0, w1, w2, w3, которые будут хранится в атрибутах w_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e33a9c22-8fac-40ef-9a30-2ff338e8d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg:                               # в целях простоты алгоритма класс реализован для трех фичей.\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w_0 = 0                        # инициализируется вес свободного члена\n",
    "        self.w_1 = 1                        # инициализируется коэффициент перед первым аргументом (переменной, x1, базисной фукнцией)\n",
    "        self.w_2 = 1\n",
    "        self.w_3 = 1\n",
    "        \n",
    "    def fit(self, X, y):                    # функция для поиска оптимальных значений коэффициентов self.w_i\n",
    "        for i in range(10000):               # всё ниже описанное будет проделано 10000 раз.\n",
    "            yhat = X.iloc[:, 0] * self.w_1 + X.iloc[:, 1] * self.w_2 + X.iloc[:, 2] * self.w_3 + self.w_0   # считаем логгиты (сырые выходы модели) с текущими \"весами\"\n",
    "            error = y.to_numpy() - yhat     # получаем колонку разниц реальных y и логгитов модели\n",
    "            gradient1 = (X.iloc[:, 0] * error).mean()   # по каждому столбцу считаем градиент как производную функции L по w (среднее значение произведений х1 и (y_pred - y_act).\n",
    "            gradient2 = (X.iloc[:, 1] * error).mean()\n",
    "            gradient3 = (X.iloc[:, 2] * error).mean()\n",
    "            gradient0 = error.mean()                    # для свободного члена просто считаем среднее значение разниц между реальным y и предсказанным.\n",
    "            self.w_1 = self.w_1 - self.learning_rate * gradient1   # меняем коэффициент перед х1 в сторону градиента с коэффициентом learning_rate.\n",
    "            self.w_2 = self.w_2 - self.learning_rate * gradient2\n",
    "            self.w_3 = self.w_3 - self.learning_rate * gradient3\n",
    "            self.w_0 = self.w_0 - self.learning_rate * gradient0   # меняем свободный член на величину градиента, умноженного на learning_rate.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c335e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.714606</td>\n",
       "      <td>-0.544703</td>\n",
       "      <td>0.843658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.709027</td>\n",
       "      <td>3.091167</td>\n",
       "      <td>0.527249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.371633</td>\n",
       "      <td>-5.706764</td>\n",
       "      <td>11.966594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.877435</td>\n",
       "      <td>10.271443</td>\n",
       "      <td>2.186386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.556441</td>\n",
       "      <td>-0.681188</td>\n",
       "      <td>1.830415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1         x2         x3  y\n",
       "0  0.714606  -0.544703   0.843658  1\n",
       "1  3.709027   3.091167   0.527249  1\n",
       "2  0.371633  -5.706764  11.966594  0\n",
       "3  4.877435  10.271443   2.186386  1\n",
       "4  4.556441  -0.681188   1.830415  0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0 = pd.read_csv('aux/LogRegtrain.csv').drop('Unnamed: 0', axis=1)\n",
    "test_0 = pd.read_csv('aux/LogRegtest.csv').drop('Unnamed: 0', axis=1)\n",
    "test_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c7c7b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.214002</td>\n",
       "      <td>-0.270562</td>\n",
       "      <td>-0.759311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.852510</td>\n",
       "      <td>0.101933</td>\n",
       "      <td>-0.873365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.450695</td>\n",
       "      <td>-0.799415</td>\n",
       "      <td>3.250090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.658852</td>\n",
       "      <td>0.837552</td>\n",
       "      <td>-0.275308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.437328</td>\n",
       "      <td>-0.284545</td>\n",
       "      <td>-0.403622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-0.991415</td>\n",
       "      <td>0.493089</td>\n",
       "      <td>-0.485842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-1.629071</td>\n",
       "      <td>1.565755</td>\n",
       "      <td>-0.597442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.006083</td>\n",
       "      <td>0.865697</td>\n",
       "      <td>-0.016956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-1.307402</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>5.507393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.634735</td>\n",
       "      <td>1.161032</td>\n",
       "      <td>-0.749610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3\n",
       "0   -1.214002 -0.270562 -0.759311\n",
       "1    0.852510  0.101933 -0.873365\n",
       "2   -1.450695 -0.799415  3.250090\n",
       "3    1.658852  0.837552 -0.275308\n",
       "4    1.437328 -0.284545 -0.403622\n",
       "..        ...       ...       ...\n",
       "195 -0.991415  0.493089 -0.485842\n",
       "196 -1.629071  1.565755 -0.597442\n",
       "197  1.006083  0.865697 -0.016956\n",
       "198 -1.307402  0.023617  5.507393\n",
       "199 -0.634735  1.161032 -0.749610\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "train[['x1', 'x2', 'x3']] = ss.fit_transform(train_0[['x1', 'x2', 'x3']] )\n",
    "train[['y']] = train_0[['y']]\n",
    "\n",
    "test[['x1', 'x2', 'x3']] = ss.transform(test_0[['x1', 'x2', 'x3']] )\n",
    "test[['y']] = test_0[['y']]\n",
    "test.iloc[:, :3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0ba88fc-2c44-4706-8837-112f70a883e1",
   "metadata": {},
   "source": [
    "Опишем метод predict, который будет предсказывать для новых точек в дальнейшем их y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36e47a75-44a3-41d7-ad28-3f399125af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg:                               \n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w_0 = 0                        \n",
    "        self.w_1 = 1                        \n",
    "        self.w_2 = 1\n",
    "        self.w_3 = 1\n",
    "        \n",
    "    def fit(self, X, y):                    \n",
    "        for i in range(10000):               \n",
    "            yhat = X.iloc[:, 0] * self.w_1 + X.iloc[:, 1] * self.w_2 + X.iloc[:, 2] * self.w_3 + self.w_0  \n",
    "            error = yhat - y.to_numpy()    \n",
    "            gradient1 = (X.iloc[:, 0] * error).mean()  \n",
    "            gradient2 = (X.iloc[:, 1] * error).mean()\n",
    "            gradient3 = (X.iloc[:, 2] * error).mean()\n",
    "            gradient0 = error.mean()                    \n",
    "            self.w_1 = self.w_1 - self.learning_rate * gradient1   \n",
    "            self.w_2 = self.w_2 - self.learning_rate * gradient2\n",
    "            self.w_3 = self.w_3 - self.learning_rate * gradient3\n",
    "            self.w_0 = self.w_0 - self.learning_rate * gradient0   \n",
    "\n",
    "    def predict(self, X):                           # функция для предсказания класса из таблицы с тремя фичами.\n",
    "        yhat = X.iloc[:, 0] * self.w_1 + X.iloc[:, 1] * self.w_2 + X.iloc[:, 2] * self.w_3 + self.w_0  # считаем предсказание как сумму произведений текущей фичи и веса, добавляем свободный член.\n",
    "        cl = pd.DataFrame()\n",
    "        cl = [0 if x < 0.5  else 1 for x in yhat]   # для предсказанных y меньше 0.5 применяем класс 0. Для остальных предсказанных у применяем класс 1.\n",
    "        return cl                                   # возвращаем датафрейм с предсказанными классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "757d5e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogReg(0.01)\n",
    "lr.fit(train[['x1', 'x2', 'x3']], train['y'])\n",
    "y_pred = lr.predict(test.iloc[:, :3])\n",
    "\n",
    "# Посчитаем количество совпавших классов.\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test[['y']], y_pred)\n",
    "\n",
    "score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baec7b96",
   "metadata": {},
   "source": [
    "Сравним результаты созданной модели с реализованной в sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e1a99e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.805"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train[['x1', 'x2', 'x3']], train['y'])\n",
    "y_pred_test = log_reg.predict(test.iloc[:, :3])\n",
    "\n",
    "score_test = accuracy_score(test[['y']], y_pred_test)\n",
    "\n",
    "score_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "893e93bc",
   "metadata": {},
   "source": [
    "Результаты выше реализованного класса и модели близки к тем, что реализованы в библиотеке sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1acc5386270fcafe1818af120099d8acd54316aa94eeac69504670abcb8f3ec4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
